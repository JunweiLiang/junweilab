<html>
<head>
  <meta  http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=1" />
  <link rel="stylesheet" type="text/css" href="utils/bootstrap.min.css"/>
  <script language="javascript" src="utils/jquery.min.js"></script>
  <script language="javascript" src="utils/bootstrap.min.js"></script>
  <!-- -->
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css"/>
  <link rel="stylesheet" type="text/css" href="utils/cssReset.css"/>
  <link rel="stylesheet" type="text/css" href="utils/css_layout.css"/>
  <title>Precognition Lab at HKUST (Guangzhou)</title>
  <!-- 搜索引擎优化stuff -->
  <meta name="description"
    content="Academic website for Prof. Junwei Liang's lab, the Precognition Lab. Dr. Junwei Liang is currently a tenure-track Assistant Professor at The Hong Kong University of Science and Technology (Guangzhou). He is also an affiliate assistant professor at HKUST computer science & engineering department. He was a senior researcher at Tencent Youtu Lab working on cutting-edge computer vision research and applications. Prior to that, he received his Ph.D. degree from Carnegie Mellon University, working with Prof. Alexander Hauptmann. He is the recipient of Baidu Scholarship and Yahoo Fellowship, and awarded Rising Star Award at the World AI Conference in 2020. He is the winner of several public safety video analysis competitions, including ASAPS and TRECVID ActEV. His work has helped and been reported by major news agencies like the Washington Post and New York Times. His research interests include human trajectory forecasting, action recognition, and large-scale computer vision and video analytics in general. His mission: develop AI technologies for social good.">
  <meta name="keywords" content="Junwei Liang,CMU,HKUST,HKUST-GZ,Professor,computer vision,PhD,梁俊卫,Carnegie Mellon University,The Hong Kong University of Science and Technology">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-156016426-1"></script>
  <script>
    // for Google Analytics, for free!
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-156016426-1');

  </script>

</head>
<body>
<div id="sidebar">
  <img class='me' src="resources/me.jpeg"></img>
  <br/>
  <div class="info">
    <h2 class="name">Lab Director:</h2>
    <h2 class="name">Prof. Junwei Liang</h2>
    <h2 class="name_chinese">梁俊卫</h2>
    <h2 class="email">HKUST (Guangzhou) / HKUST</h2>
    <h2 class="email">Office: E4-304</h2>
    <h2 class="link">
      <a style="font-size: 14px; color: yellow; font-weight: bold;" href="https://junweiliang.me">Personal Page</a>
    </h2>
  <!--
    <h2 class="link">
      <a href="https://www.semanticscholar.org/author/Junwei-Liang/1915796">[Semantic Scholar]</a>
      <a href="https://www.researchgate.net/profile/Junwei_Liang3">[Research Gate]</a>
    </h2>
    <h2 class="link">
      <a href="https://github.com/JunweiLiang">[Github]</a>
      <a href="https://www.linkedin.com/in/junweiliang/">[LinkedIn]</a>
      <a href="https://www.youtube.com/channel/UC-z7ZWp8Rbu2xhxnbAL_bRQ">[Youtube]</a>
    </h2>
    <h2 class="link">
      <a href="https://www.zhihu.com/people/junwei-liang-50">[知乎]</a>
      <a href="https://www.xiaohongshu.com/user/profile/62c3a783000000001b02b099">[小红书]</a>
      <a href="https://twitter.com/JunweilLiang">[Twitter]</a>
    </h2>
  -->

  </div>
  <div id="navigation">
    <a class="nav_item" href="./index.html">
      <i class="icon icon-home icon-white"></i> &nbsp; About
    </a>
    <a class="nav_item" href="./index.html#publications">
      <i class="icon icon-th-large icon-white icon-list"></i> &nbsp; Publications
    </a>
    <a class="nav_item" href="./projects.html#projects">
      <i class="icon icon-th-large icon-white"></i> &nbsp; Projects
    </a>
    <a class="nav_item" href="./index.html#members">
      <i class="icon icon-white icon-user"></i> &nbsp; Lab Members
    </a>
    <a class="nav_item" href="./internal/index.html">
      <i class="icon icon-book icon-white"></i> &nbsp; Internal Docs
    </a>

  </div>
</div>

<style type="text/css">
  #main{
    background: #f7f7f7;
  }
  #main > div.publications > ol > li{
    background: white;
    box-shadow: 2px 5px 5px #c9c9c9;
    margin-bottom: 10px;
    padding: 20px;
  }
  #main div.img{
    padding: 20px;
    text-align: center;
    padding-right: 150px;
  }
  #main div.img > div.img_caption{
    font-weight: 450;
    font-size: 1.1em;
    line-height: 40px;
  }
</style>
<div id="main">

  <div class="title">
    <a class="title_link" id="projects" href="#projects">Projects</a>
  </div>

  <div class="content">
    <ul>
      <li>Research Roadmap Slides <a href="https://docs.google.com/presentation/d/1C1raWd6a0Df7ZOK8dj4ZQLld2YQ0xqDf3h2vSgLnJZg/edit?usp=sharing">[中文版]</a> [English version]</li>

      <li>Machine Perception of Human Activities
        <ul>
          <li>Efficient long-term action detection in extended videos <a href="http://openaccess.thecvf.com/content_WACVW_2020/papers/w5/Liu_Argus_Efficient_Activity_Detection_System_for_Extended_Video_Analysis_WACVW_2020_paper.pdf">[CMU-DIVA]</a></li>
          <li>End-to-end action detection <a href="https://github.com/JunweiLiang/aicity_action">[Stargazer]</a></li>
          <li>Multi-modal multi-dataset model co-training [<a href="https://arxiv.org/abs/2209.12362">NeurIPS'22</a>, <a href="https://arxiv.org/abs/2209.13307">NeurIPS'22</a>]</li>
          <li>Zero-shot / Few-shot action recognition</li>
          <li>First-person / ego-centric view action recognition & 3D action recognition & Viewpoint invariant representation [<a href="https://arxiv.org/pdf/2012.02426.pdf">Example</a>]</li>
          <li>Learning from 3D simulation <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Liang_The_Garden_of_Forking_Paths_Towards_Multi-Future_Trajectory_Prediction_CVPR_2020_paper.pdf">[ForkingPaths]</a>, <a href="https://arxiv.org/pdf/2004.02022.pdf">[SimAug]</a>, <a href="https://github.com/JunweiLiang/Multiverse/tree/master/forking_paths_dataset">[CARLA Sim]</a></li>
        </ul>
      </li>
      <li>Future Prediction
        <ul>
          <li>
            Action Anticipation & Human Intention Prediction <a href="https://github.com/JunweiLiang/next-prediction">[Next-prediction]</a>
            <ul>
              <li>Sub-direction: Predictive Self-supervised Learning</li>
              <li>Sub-direction: Video Generation, Generative Model - Diffusion Model</li>
            </ul>
          </li>
          <li>Trajectory Prediction <a href="https://github.com/JunweiLiang/Multiverse">[Multiverse]</a></li>
          <li>Time-series Forecasting (weather, energy, economics, etc.)</li>
        </ul>
      </li>
      <li>AI + X
        <ul>
          <li>Aerial Video analysis <a href="https://www.cmu.edu/news/stories/archives/2020/august/drones-hurricane-damage.html">[natural disaster assessment using drone videos - WACV’21]</a></li>
          <li>Robotic Helper (Robotic Third Hand) <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=1650994">[NSF grant]</a></li>
          <li>Medical Image Analysis <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhu_Weakly_Supervised_3D_Semantic_Segmentation_Using_Cross-Image_Consensus_and_Inter-Voxel_ICCV_2021_paper.pdf">[3D semantic segmentation with cryo-ET images (for protein molecule)]</a></li>
        </ul>
      </li>
      <li>Edge Computing
        <ul>
          <li>Efficient PPL/Model Design <a href="https://github.com/JunweiLiang/Object_Detection_Tracking">[ODT]</a></li>
          <li>Knowledge Distillation</li>
        </ul>
      </li>
    </ul>



    <div class="img">
      <img src="resources/project_overview_092022.jpg"></img>
      <div class="img_caption">Figure 1. Project overview of the Precognition group (09/2022)</div>
    </div>
  </div>

  <div class="title">
    <a class="title_link" id="media" href="#media">Demos / Project Sites</a>
  </div>

  <div class="content">
    <ul>
      <li>
        <span style="font-weight: bold">ChatGPT + Robotics @Jacobi.ai</span>
        [<a href="https://mp.weixin.qq.com/s/otlRTlOEET3ldJ3URqw8AQ">Demo1</a>]
        [<a href="https://mp.weixin.qq.com/s/Gx65LpDEWdwBYfbP-m2Esw">Demo2</a>]
        [<a href="https://36kr.jp/248510/">News Report</a>]
      </li>
      <li>
        <span style="font-weight: bold">Pedestrian Trajectory Prediction</span>
        [<a href="next/">Next-Prediction</a>] [<a href="next/multiverse">Multiverse</a>]
      </li>
      <li>
        <span style="font-weight: bold">Efficient Action Detection</span>
      </li>
      <li>
        <span style="font-weight: bold">Zero-shot Video Retrieval</span>
      </li>
      <li>
        <span style="font-weight: bold">3D Event Reconstruction</span>
        [<a href="vera3d/">VERA</a>]
      </li>
      <li>
        <span style="font-weight: bold">Multimodal Question Answering</span>
        [<a href="memexqa/">MemexQA</a>]
      </li>

    </ul>
  </div>

</div>


<!--
	a Junwei Liang's production
	contact: junweiliang1114@gmail.com
-->
</body>
</html>
